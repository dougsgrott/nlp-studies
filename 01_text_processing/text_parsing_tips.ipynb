{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f408e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import copy\n",
    "import re\n",
    "import textwrap\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from nltk.corpus import words as nltk_words, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from IPython.display import HTML\n",
    "\n",
    "import spacy\n",
    "import enchant\n",
    "from collections import OrderedDict\n",
    "import contractions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Download required resources\n",
    "# nltk.download('words')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d11c7",
   "metadata": {},
   "source": [
    "## Tip 1: Know when and how to filter your words and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "76\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "# text = \"The researchers were studying the behaviors of 10 wolves that had been running, hunted, and howling throughout the forested regions. Interestingly, they noticed that the wolves’ activities varied depending on the season, with increased aggression observed during mating periods. The observation included analyzing journals written by those documenting the wolves’ movements and strategies for surviving in harsh environments. Understanding these interactions helps in predicting future behavioral patterns and classifying different subspecies accordingly.\"\n",
    "# text = \"It's Monday, and the researchers were studying the behaviors of 10 wolves that had been running, hunted, and howling throughout the forested regions. Interestingly, they noticed that the wolves’ activities varied depending on the season, with increased aggression observed during mating periods. The observation included analyzing journals written by those documenting the wolves’ movements and strategies for surviving in harsh environments. Understanding these interactions helps in predicting future behavioral patterns and classifying different subspecies accordingly.\"\n",
    "text = \"It's Monday, and the researchers were studying the behaviors of 10 wolves that had been running, hunted, and howling throughout the forested regions. Interestingly, they noticed that the wolves’ activities varied depending on the season, with increased aggression observed during mating periods. The observation included analyzing journals written by those documenting the wolves’ movements and strategies for surviving in harsh environments. Understanding these interactions helps in predicting future behavioral patterns and classifying different subspecies accordingly.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "spacy_tokens_with_punct = [token.text for token in doc]\n",
    "spacy_tokens_wout_punct = [token.text for token in doc if not token.is_punct and not token.is_space]\n",
    "spacy_tokens_alpha = [token.text for token in doc if token.is_alpha]\n",
    "\n",
    "print(len(spacy_tokens_with_punct))\n",
    "print(len(spacy_tokens_wout_punct))\n",
    "print(len(spacy_tokens_alpha))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35629169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_ascii</th>\n",
       "      <th>is_bracket</th>\n",
       "      <th>is_currency</th>\n",
       "      <th>is_digit</th>\n",
       "      <th>is_left_punct</th>\n",
       "      <th>is_lower</th>\n",
       "      <th>is_oov</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_right_punct</th>\n",
       "      <th>is_sent_end</th>\n",
       "      <th>is_sent_start</th>\n",
       "      <th>is_space</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_title</th>\n",
       "      <th>is_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>It</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifying</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subspecies</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accordingly</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_alpha  is_ascii  is_bracket  is_currency  is_digit  \\\n",
       "It               True      True       False        False     False   \n",
       "'s              False      True       False        False     False   \n",
       "Monday           True      True       False        False     False   \n",
       ",               False      True       False        False     False   \n",
       "and              True      True       False        False     False   \n",
       "...               ...       ...         ...          ...       ...   \n",
       "classifying      True      True       False        False     False   \n",
       "different        True      True       False        False     False   \n",
       "subspecies       True      True       False        False     False   \n",
       "accordingly      True      True       False        False     False   \n",
       ".               False      True       False        False     False   \n",
       "\n",
       "             is_left_punct  is_lower  is_oov  is_punct  is_quote  \\\n",
       "It                   False     False    True     False     False   \n",
       "'s                   False      True    True     False     False   \n",
       "Monday               False     False    True     False     False   \n",
       ",                    False     False    True      True     False   \n",
       "and                  False      True    True     False     False   \n",
       "...                    ...       ...     ...       ...       ...   \n",
       "classifying          False      True    True     False     False   \n",
       "different            False      True    True     False     False   \n",
       "subspecies           False      True    True     False     False   \n",
       "accordingly          False      True    True     False     False   \n",
       ".                    False     False    True      True     False   \n",
       "\n",
       "             is_right_punct  is_sent_end  is_sent_start  is_space  is_stop  \\\n",
       "It                    False        False           True     False     True   \n",
       "'s                    False        False          False     False     True   \n",
       "Monday                False        False          False     False    False   \n",
       ",                     False        False          False     False    False   \n",
       "and                   False        False          False     False     True   \n",
       "...                     ...          ...            ...       ...      ...   \n",
       "classifying           False        False          False     False    False   \n",
       "different             False        False          False     False    False   \n",
       "subspecies            False        False          False     False    False   \n",
       "accordingly           False        False          False     False    False   \n",
       ".                     False         True          False     False    False   \n",
       "\n",
       "             is_title  is_upper  \n",
       "It               True     False  \n",
       "'s              False     False  \n",
       "Monday           True     False  \n",
       ",               False     False  \n",
       "and             False     False  \n",
       "...               ...       ...  \n",
       "classifying     False     False  \n",
       "different       False     False  \n",
       "subspecies      False     False  \n",
       "accordingly     False     False  \n",
       ".               False     False  \n",
       "\n",
       "[87 rows x 17 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f_list must be strings (names of attributes)\n",
    "f_list = [\n",
    "    \"is_alpha\", \"is_ascii\", \"is_bracket\", \"is_currency\", \"is_digit\",\n",
    "    \"is_left_punct\", \"is_lower\", \"is_oov\", \"is_punct\", \"is_quote\",\n",
    "    \"is_right_punct\", \"is_sent_end\", \"is_sent_start\", \"is_space\",\n",
    "    \"is_stop\", \"is_title\", \"is_upper\"\n",
    "]\n",
    "\n",
    "# Now correctly access each attribute with getattr\n",
    "results = [[getattr(token, attr) for attr in f_list] for token in doc]\n",
    "\n",
    "# Show result\n",
    "# for attr_name, value in zip(f_list, results):\n",
    "#     print(f\"{attr_name}: {value}\")\n",
    "\n",
    "# results, \n",
    "pd.DataFrame(data=results, columns=f_list, index=doc)\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e457b",
   "metadata": {},
   "source": [
    "## Tip 2: Detecting english words with pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e50a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Is English?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yesterday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>booked</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>table</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>at</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>new</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Italian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>called</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Trattoria</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>focaccia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>and</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bruschetta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>were</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>great</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>but</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cannoli</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>was</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>too</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sweet</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  Is English?\n",
       "0    Yesterday         True\n",
       "1            I         True\n",
       "2       booked         True\n",
       "3            a         True\n",
       "4        table         True\n",
       "5           at         True\n",
       "6            a         True\n",
       "7          new         True\n",
       "8      Italian         True\n",
       "9   restaurant         True\n",
       "10      called         True\n",
       "11   Trattoria        False\n",
       "12         The         True\n",
       "13    focaccia        False\n",
       "14         and         True\n",
       "15  bruschetta        False\n",
       "16        were         True\n",
       "17       great         True\n",
       "18         but         True\n",
       "19         the         True\n",
       "20     cannoli        False\n",
       "21         was         True\n",
       "22         too         True\n",
       "23       sweet         True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import enchant\n",
    "import pandas as pd\n",
    "\n",
    "text = \"Yesterday, I booked a table at a new Italian restaurant called Trattoria. The focaccia and bruschetta were great, but the cannoli was too sweet.\"\n",
    "# text = \"Yesterday, I booked a table at a new Mexican restaurant called Los Cumpadres. The enchiladas and chilaquiles were pretty tasty, but too spicy.\"\n",
    "\n",
    "# Load English dictionary\n",
    "english_dict = enchant.Dict(\"en_US\")\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenization and checking\n",
    "tokens = [token.text for token in doc if not token.is_space and not token.is_punct]\n",
    "\n",
    "# Check if each token is an English word\n",
    "is_english = [english_dict.check(token) for token in tokens]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Token\": tokens,\n",
    "    \"Is English?\": is_english\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e543222",
   "metadata": {},
   "source": [
    "## Tip 3: Expand contractions using the contractions package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74efa992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: I'm learning NLP and it's amazing!\n",
      "Expanded text: I am learning NLP and it is amazing!\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "# Example text with contractions\n",
    "text = \"I'm learning NLP and it's amazing!\" # I can't believe how easy it's getting.\n",
    "\n",
    "# Expand contractions\n",
    "expanded_text = contractions.fix(text)\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Expanded text: {expanded_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc71113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with_punct</th>\n",
       "      <th>without_punct</th>\n",
       "      <th>alpha_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'m</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         with_punct without_punct alpha_only\n",
       "I                 X             X          X\n",
       "'m                X             X           \n",
       "learning          X             X          X\n",
       "NLP               X             X          X\n",
       "and               X             X          X\n",
       "it                X             X          X\n",
       "'s                X             X           \n",
       "amazing           X             X          X\n",
       "!                 X                         "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Text\n",
    "text = \"I'm learning NLP and it's amazing!\"  # I can't believe how easy it's getting.\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Create the three lists\n",
    "spacy_tokens_with_punct = [token.text for token in doc]\n",
    "spacy_tokens_wout_punct = [token.text for token in doc if not token.is_punct]\n",
    "spacy_tokens_alpha = [token.text for token in doc if token.is_alpha]\n",
    "\n",
    "# Create the unique index based on all tokens (with punctuations)\n",
    "tokens = spacy_tokens_with_punct\n",
    "\n",
    "# Build the DataFrame\n",
    "df = pd.DataFrame(index=tokens)\n",
    "\n",
    "# Fill columns\n",
    "df[\"with_punct\"] = df.index.map(lambda x: 'X' if x in spacy_tokens_with_punct else '')\n",
    "df[\"without_punct\"] = df.index.map(lambda x: 'X' if x in spacy_tokens_wout_punct else '')\n",
    "df[\"alpha_only\"] = df.index.map(lambda x: 'X' if x in spacy_tokens_alpha else '')\n",
    "\n",
    "\n",
    "print(len(spacy_tokens_with_punct))\n",
    "print(len(spacy_tokens_wout_punct))\n",
    "print(len(spacy_tokens_alpha))\n",
    "\n",
    "\n",
    "# Display\n",
    "df\n",
    "\n",
    "## Now, add the english word column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bfcd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
